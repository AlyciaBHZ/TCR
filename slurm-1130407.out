========================================
FlowTCR-Gen (Stage 2) Training
========================================
Job: 1130407 on zgpuA1003
Start: Thu Dec  4 13:47:10 +08 2025
Mode: ABLATION - No CFG (drop_prob=0)
Output: flowtcr_fold/FlowTCR_Gen/saved_model/stage2/ablation_no_cfg
Log: flowtcr_fold/FlowTCR_Gen/saved_model/stage2/ablation_no_cfg/train_1130407.log
GPU: NVIDIA A100 80GB PCIe
========================================
üöÄ FlowTCR-Gen Training (Stage 2)
   Device: cuda
   Ablation: no_cfg
   Vocab size: 25
[FlowTCRGenDataset] Filtered 209407 -> 209407 (require cdr3_b)
[FlowTCRGenDataset] Loaded 209407 samples from flowtcr_fold/data/trn.jsonl
[FlowTCRGenDataset] Filtered 24020 -> 24020 (require cdr3_b)
[FlowTCRGenDataset] Loaded 24020 samples from flowtcr_fold/data/val.jsonl
   Model parameters: 5,334,631

üèÉ Starting training from epoch 1
  [Epoch 1 Batch 50] loss=0.0550 mse=0.0870
  [Epoch 1 Batch 100] loss=0.0324 mse=0.0645
  [Epoch 1 Batch 150] loss=0.0135 mse=0.0456
  [Epoch 1 Batch 200] loss=0.0078 mse=0.0399
  [Epoch 1 Batch 250] loss=0.0052 mse=0.0374
  [Epoch 1 Batch 300] loss=0.0034 mse=0.0356
  [Epoch 1 Batch 350] loss=0.0022 mse=0.0344
  [Epoch 1 Batch 400] loss=-0.0001 mse=0.0320
  [Epoch 1 Batch 450] loss=-0.0007 mse=0.0314
  [Epoch 1 Batch 500] loss=-0.0019 mse=0.0303
  [Epoch 1 Batch 550] loss=-0.0026 mse=0.0295
  [Epoch 1 Batch 600] loss=-0.0042 mse=0.0279
  [Epoch 1 Batch 650] loss=-0.0067 mse=0.0255
  [Epoch 1 Batch 700] loss=-0.0062 mse=0.0259
  [Epoch 1 Batch 750] loss=-0.0071 mse=0.0251
  [Epoch 1 Batch 800] loss=-0.0089 mse=0.0233
  [Epoch 1 Batch 850] loss=-0.0156 mse=0.0165
  [Epoch 1 Batch 900] loss=-0.0139 mse=0.0181
  [Epoch 1 Batch 950] loss=-0.0172 mse=0.0148
  [Epoch 1 Batch 1000] loss=-0.0204 mse=0.0116
  [Epoch 1 Batch 1050] loss=-0.0205 mse=0.0115
  [Epoch 1 Batch 1100] loss=-0.0219 mse=0.0100
  [Epoch 1 Batch 1150] loss=-0.0219 mse=0.0101
  [Epoch 1 Batch 1200] loss=-0.0227 mse=0.0092
  [Epoch 1 Batch 1250] loss=-0.0227 mse=0.0093
  [Epoch 1 Batch 1300] loss=-0.0234 mse=0.0086
  [Epoch 1 Batch 1350] loss=-0.0255 mse=0.0065
  [Epoch 1 Batch 1400] loss=-0.0265 mse=0.0054
  [Epoch 1 Batch 1450] loss=-0.0241 mse=0.0078
  [Epoch 1 Batch 1500] loss=-0.0245 mse=0.0074
  [Epoch 1 Batch 1550] loss=-0.0248 mse=0.0071
  [Epoch 1 Batch 1600] loss=-0.0272 mse=0.0046
  [Epoch 1 Batch 1650] loss=-0.0261 mse=0.0058
  [Epoch 1 Batch 1700] loss=-0.0270 mse=0.0049
  [Epoch 1 Batch 1750] loss=-0.0283 mse=0.0035
  [Epoch 1 Batch 1800] loss=-0.0286 mse=0.0032
  [Epoch 1 Batch 1850] loss=-0.0272 mse=0.0047
  [Epoch 1 Batch 1900] loss=-0.0279 mse=0.0040
  [Epoch 1 Batch 1950] loss=-0.0290 mse=0.0029
  [Epoch 1 Batch 2000] loss=-0.0266 mse=0.0053
  [Epoch 1 Batch 2050] loss=-0.0285 mse=0.0034
  [Epoch 1 Batch 2100] loss=-0.0289 mse=0.0030
  [Epoch 1 Batch 2150] loss=-0.0275 mse=0.0044
  [Epoch 1 Batch 2200] loss=-0.0294 mse=0.0025
  [Epoch 1 Batch 2250] loss=-0.0297 mse=0.0021
  [Epoch 1 Batch 2300] loss=-0.0288 mse=0.0031
  [Epoch 1 Batch 2350] loss=-0.0280 mse=0.0039
  [Epoch 1 Batch 2400] loss=-0.0304 mse=0.0015
  [Epoch 1 Batch 2450] loss=-0.0298 mse=0.0021
  [Epoch 1 Batch 2500] loss=-0.0277 mse=0.0042
  [Epoch 1 Batch 2550] loss=-0.0277 mse=0.0042
  [Epoch 1 Batch 2600] loss=-0.0291 mse=0.0028
  [Epoch 1 Batch 2650] loss=-0.0299 mse=0.0020
  [Epoch 1 Batch 2700] loss=-0.0287 mse=0.0032
  [Epoch 1 Batch 2750] loss=-0.0291 mse=0.0027
  [Epoch 1 Batch 2800] loss=-0.0279 mse=0.0040
  [Epoch 1 Batch 2850] loss=-0.0288 mse=0.0031
  [Epoch 1 Batch 2900] loss=-0.0298 mse=0.0020
  [Epoch 1 Batch 2950] loss=-0.0296 mse=0.0023
  [Epoch 1 Batch 3000] loss=-0.0296 mse=0.0023
  [Epoch 1 Batch 3050] loss=-0.0298 mse=0.0020
  [Epoch 1 Batch 3100] loss=-0.0291 mse=0.0028
  [Epoch 1 Batch 3150] loss=-0.0287 mse=0.0032
