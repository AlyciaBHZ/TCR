#!/usr/bin/env python
"""
Phase 0 è‡ªåŠ¨åŒ–ç®¡çº¿è„šæœ¬
======================

æµç¨‹:
1. æ£€æŸ¥ batch*.txt é‡Œçš„ PDB ID æ˜¯å¦å…¨éƒ¨ä¸‹è½½
2. æœªå®Œæˆåˆ™ sleep 30 åˆ†é’Ÿåé‡è¯•
3. ä¸‹è½½å®Œæˆåè¿è¡Œ preprocessï¼ˆè·³è¿‡å·²å­˜åœ¨çš„ .npzï¼‰
4. æœ€åè¿è¡Œ EvoEF2 æ‰¹é‡èƒ½é‡è®¡ç®—

Usage:
    python flowtcr_fold/TCRFold_Light/process_pdb/run_phase0_pipeline.py

    # æˆ–åå°è¿è¡Œ
    nohup python flowtcr_fold/TCRFold_Light/process_pdb/run_phase0_pipeline.py \
        > logs/phase0_pipeline.log 2>&1 &
"""

import argparse
import logging
import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import List, Set, Tuple

# ============================================================================
# é…ç½®
# ============================================================================

DEFAULT_CONFIG = {
    "batch_files": [
        "flowtcr_fold/data/pdb/batch1.txt",
        "flowtcr_fold/data/pdb/batch2.txt",
        "flowtcr_fold/data/pdb/batch3.txt",
        "flowtcr_fold/data/pdb/batch4.txt",
        "flowtcr_fold/data/pdb/batch5.txt",
    ],
    "raw_dir": "flowtcr_fold/data/pdb_structures/raw",
    "processed_dir": "flowtcr_fold/data/pdb_structures/processed",
    "energy_cache": "flowtcr_fold/data/energy_cache.jsonl",
    "log_dir": "flowtcr_fold/logs",
    "sleep_minutes": 30,
    "check_interval_seconds": 10,  # æ£€æŸ¥ä¸‹è½½è¿›åº¦çš„é—´éš”
}


# ============================================================================
# æ—¥å¿—è®¾ç½®
# ============================================================================

def setup_logging(log_dir: str) -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°ã€‚"""
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"phase0_pipeline_{timestamp}.log")
    
    logger = logging.getLogger("Phase0Pipeline")
    logger.setLevel(logging.INFO)
    
    # æ–‡ä»¶ handler
    fh = logging.FileHandler(log_file)
    fh.setLevel(logging.INFO)
    
    # æ§åˆ¶å° handler
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    
    # æ ¼å¼
    formatter = logging.Formatter(
        "[%(asctime)s] %(levelname)s - %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    
    logger.addHandler(fh)
    logger.addHandler(ch)
    
    logger.info(f"æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    return logger


# ============================================================================
# Step 1: æ£€æŸ¥ä¸‹è½½è¿›åº¦
# ============================================================================

def load_all_pdb_ids(batch_files: List[str]) -> Set[str]:
    """ä» batch æ–‡ä»¶åŠ è½½æ‰€æœ‰ PDB IDã€‚"""
    all_ids = set()
    
    for batch_file in batch_files:
        if not os.path.exists(batch_file):
            continue
        with open(batch_file, 'r') as f:
            content = f.read()
            # æ”¯æŒé€—å·åˆ†éš”å’Œæ¢è¡Œåˆ†éš”
            for part in content.replace('\n', ',').split(','):
                pdb_id = part.strip().upper()
                if pdb_id and len(pdb_id) == 4:
                    all_ids.add(pdb_id)
    
    return all_ids


def get_downloaded_ids(raw_dir: str) -> Set[str]:
    """è·å–å·²ä¸‹è½½çš„ PDB IDã€‚"""
    downloaded = set()
    raw_path = Path(raw_dir)
    
    if not raw_path.exists():
        return downloaded
    
    for f in raw_path.glob("*.pdb"):
        pdb_id = f.stem.upper()
        downloaded.add(pdb_id)
    
    # ä¹Ÿæ£€æŸ¥ .cif æ–‡ä»¶
    for f in raw_path.glob("*.cif"):
        pdb_id = f.stem.upper()
        downloaded.add(pdb_id)
    
    return downloaded


def check_download_progress(
    batch_files: List[str], 
    raw_dir: str, 
    logger: logging.Logger
) -> Tuple[int, int, Set[str]]:
    """
    æ£€æŸ¥ä¸‹è½½è¿›åº¦ã€‚
    
    Returns:
        (total, downloaded, missing_ids)
    """
    all_ids = load_all_pdb_ids(batch_files)
    downloaded_ids = get_downloaded_ids(raw_dir)
    
    missing_ids = all_ids - downloaded_ids
    
    total = len(all_ids)
    downloaded = len(downloaded_ids)
    
    logger.info(f"ä¸‹è½½è¿›åº¦: {downloaded}/{total} ({100*downloaded/total:.1f}%)")
    
    if missing_ids:
        # æ˜¾ç¤ºéƒ¨åˆ†ç¼ºå¤±çš„ ID
        sample = list(missing_ids)[:10]
        logger.info(f"ç¼ºå¤±æ ·æœ¬ (å‰10ä¸ª): {sample}")
    
    return total, downloaded, missing_ids


def wait_for_download(
    batch_files: List[str],
    raw_dir: str,
    sleep_minutes: int,
    logger: logging.Logger,
    min_completion_ratio: float = 0.95,
    stable_check_count: int = 2
) -> bool:
    """
    ç­‰å¾…ä¸‹è½½å®Œæˆæˆ–ç¨³å®šã€‚
    
    Args:
        min_completion_ratio: æœ€ä½å®Œæˆæ¯”ä¾‹ (é»˜è®¤ 95%)
        stable_check_count: è¿ç»­ç¨³å®šæ£€æŸ¥æ¬¡æ•° (é»˜è®¤ 2 æ¬¡æ— å˜åŒ–åˆ™è®¤ä¸ºå®Œæˆ)
    
    Returns:
        True å¦‚æœä¸‹è½½å®Œæˆ/ç¨³å®šï¼ŒFalse å¦‚æœè¢«ä¸­æ–­
    """
    prev_downloaded = 0
    stable_count = 0
    
    while True:
        total, downloaded, missing = check_download_progress(batch_files, raw_dir, logger)
        
        # å®Œæˆæ¡ä»¶ 1: 100% ä¸‹è½½
        if downloaded >= total:
            logger.info("âœ… æ‰€æœ‰ PDB æ–‡ä»¶ä¸‹è½½å®Œæˆï¼")
            return True
        
        # å®Œæˆæ¡ä»¶ 2: è¾¾åˆ°æœ€ä½æ¯”ä¾‹ä¸”ä¸‹è½½æ•°é‡ç¨³å®š
        completion_ratio = downloaded / total if total > 0 else 0
        
        if completion_ratio >= min_completion_ratio:
            if downloaded == prev_downloaded:
                stable_count += 1
                logger.info(f"ä¸‹è½½æ•°é‡ç¨³å®š ({stable_count}/{stable_check_count})")
                
                if stable_count >= stable_check_count:
                    logger.info(f"âœ… ä¸‹è½½ç¨³å®šåœ¨ {completion_ratio*100:.1f}%ï¼Œç»§ç»­å¤„ç†")
                    logger.info(f"   (å‰©ä½™ {len(missing)} ä¸ªå¯èƒ½ä¸å¯ç”¨)")
                    return True
            else:
                stable_count = 0
        
        prev_downloaded = downloaded
        
        logger.info(f"ä¸‹è½½è¿›åº¦ {completion_ratio*100:.1f}%ï¼Œç­‰å¾… {sleep_minutes} åˆ†é’Ÿ...")
        logger.info(f"è¿˜éœ€ä¸‹è½½: {len(missing)} ä¸ªæ–‡ä»¶")
        
        try:
            time.sleep(sleep_minutes * 60)
        except KeyboardInterrupt:
            logger.warning("ç”¨æˆ·ä¸­æ–­ç­‰å¾…")
            return False


# ============================================================================
# Step 2: é¢„å¤„ç† (è·³è¿‡å·²å­˜åœ¨çš„)
# ============================================================================

def get_processed_pairs(processed_dir: str) -> Set[str]:
    """è·å–å·²å¤„ç†çš„ PPI å¯¹ (ä» .npz æ–‡ä»¶å)ã€‚"""
    processed = set()
    processed_path = Path(processed_dir)
    
    if not processed_path.exists():
        return processed
    
    for f in processed_path.glob("*.npz"):
        processed.add(f.stem)
    
    return processed


def run_preprocess(
    raw_dir: str,
    processed_dir: str,
    logger: logging.Logger
) -> bool:
    """
    è¿è¡Œé¢„å¤„ç†è„šæœ¬ã€‚
    
    Returns:
        True å¦‚æœæˆåŠŸ
    """
    # æ£€æŸ¥å·²å¤„ç†çš„æ•°é‡
    existing = get_processed_pairs(processed_dir)
    logger.info(f"å·²æœ‰ {len(existing)} ä¸ª .npz æ–‡ä»¶")
    
    # è·å–å¾…å¤„ç†çš„ PDB æ–‡ä»¶
    raw_path = Path(raw_dir)
    all_pdbs = list(raw_path.glob("*.pdb"))
    logger.info(f"åŸå§‹ PDB æ–‡ä»¶æ•°: {len(all_pdbs)}")
    
    # è¿è¡Œé¢„å¤„ç†è„šæœ¬
    script_path = "flowtcr_fold/TCRFold_Light/process_pdb/preprocess_ppi_pairs.py"
    
    if not os.path.exists(script_path):
        logger.error(f"é¢„å¤„ç†è„šæœ¬ä¸å­˜åœ¨: {script_path}")
        return False
    
    cmd = [
        sys.executable, script_path,
        "--pdb_dir", raw_dir,
        "--out_dir", processed_dir,
        "--cutoff", "8.0",
        "--min_len", "30",
        "--min_contacts", "10"
    ]
    
    logger.info(f"è¿è¡Œé¢„å¤„ç†: {' '.join(cmd)}")
    
    try:
        # ä½¿ç”¨ subprocess.Popen å®æ—¶è¾“å‡º
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1
        )
        
        # å®æ—¶è¯»å–è¾“å‡º
        line_count = 0
        for line in process.stdout:
            line = line.strip()
            if line:
                # æ¯ 100 è¡Œè®°å½•ä¸€æ¬¡ï¼Œæˆ–è€…åŒ…å«å…³é”®ä¿¡æ¯çš„è¡Œ
                line_count += 1
                if line_count % 100 == 0 or "error" in line.lower() or "warning" in line.lower():
                    logger.info(f"[preprocess] {line}")
        
        process.wait()
        
        if process.returncode != 0:
            logger.error(f"é¢„å¤„ç†å¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
            return False
        
        # æ£€æŸ¥ç»“æœ
        new_count = len(get_processed_pairs(processed_dir))
        logger.info(f"âœ… é¢„å¤„ç†å®Œæˆï¼ç°æœ‰ {new_count} ä¸ª .npz æ–‡ä»¶ (æ–°å¢ {new_count - len(existing)})")
        
        return True
        
    except Exception as e:
        logger.error(f"é¢„å¤„ç†å¼‚å¸¸: {e}")
        return False


# ============================================================================
# Step 3: EvoEF2 èƒ½é‡è®¡ç®—
# ============================================================================

def get_computed_energies(energy_cache: str) -> Set[str]:
    """è·å–å·²è®¡ç®—èƒ½é‡çš„ PDB IDã€‚"""
    computed = set()
    
    if not os.path.exists(energy_cache):
        return computed
    
    import json
    with open(energy_cache, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                entry = json.loads(line)
                pdb_id = entry.get("pdb_id", "")
                if pdb_id:
                    computed.add(pdb_id)
            except:
                continue
    
    return computed


def run_evoef2_batch(
    raw_dir: str,
    energy_cache: str,
    logger: logging.Logger
) -> bool:
    """
    è¿è¡Œ EvoEF2 æ‰¹é‡èƒ½é‡è®¡ç®—ã€‚
    
    Returns:
        True å¦‚æœæˆåŠŸ
    """
    # æ£€æŸ¥å·²è®¡ç®—çš„æ•°é‡
    existing = get_computed_energies(energy_cache)
    logger.info(f"å·²æœ‰ {len(existing)} ä¸ªèƒ½é‡è®°å½•")
    
    # æ£€æŸ¥ EvoEF2 æ˜¯å¦å¯ç”¨
    evoef_path = "flowtcr_fold/tools/EvoEF2/EvoEF2"
    if not os.path.exists(evoef_path):
        logger.error(f"EvoEF2 å¯æ‰§è¡Œæ–‡ä»¶ä¸å­˜åœ¨: {evoef_path}")
        logger.error("è¯·å…ˆè¿è¡Œ: cd flowtcr_fold/tools/EvoEF2 && ./build.sh")
        return False
    
    script_path = "flowtcr_fold/TCRFold_Light/process_pdb/compute_evoef2_batch.py"
    
    if not os.path.exists(script_path):
        logger.error(f"èƒ½é‡è®¡ç®—è„šæœ¬ä¸å­˜åœ¨: {script_path}")
        return False
    
    # è®¾ç½® PYTHONPATH ä»¥ä¾¿æ‰¾åˆ° flowtcr_fold æ¨¡å—
    env = os.environ.copy()
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
    env["PYTHONPATH"] = project_root + ":" + env.get("PYTHONPATH", "")
    
    cmd = [
        sys.executable, script_path,
        "--pdb_dir", raw_dir,
        "--output", energy_cache,
        "--repair",  # ä¿®å¤ç»“æ„
        "--append"   # è¿½åŠ æ¨¡å¼ï¼Œè·³è¿‡å·²è®¡ç®—çš„
    ]
    
    logger.info(f"è¿è¡Œ EvoEF2 èƒ½é‡è®¡ç®—: {' '.join(cmd)}")
    
    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            env=env
        )
        
        # å®æ—¶è¯»å–è¾“å‡ºå¹¶è®°å½•
        ok_count = 0
        skip_count = 0
        warn_count = 0
        
        for line in process.stdout:
            line = line.strip()
            if not line:
                continue
            
            if line.startswith("[OK]"):
                ok_count += 1
                if ok_count % 100 == 0:
                    logger.info(f"[EvoEF2] å·²å¤„ç† {ok_count} ä¸ªç»“æ„...")
            elif line.startswith("[SKIP]"):
                skip_count += 1
            elif line.startswith("[WARN]"):
                warn_count += 1
                logger.warning(f"[EvoEF2] {line}")
            else:
                logger.info(f"[EvoEF2] {line}")
        
        process.wait()
        
        if process.returncode != 0:
            logger.error(f"EvoEF2 è®¡ç®—å¤±è´¥ï¼Œè¿”å›ç : {process.returncode}")
            return False
        
        # æ£€æŸ¥ç»“æœ
        new_count = len(get_computed_energies(energy_cache))
        logger.info(f"âœ… EvoEF2 è®¡ç®—å®Œæˆï¼")
        logger.info(f"   æˆåŠŸ: {ok_count}, è·³è¿‡: {skip_count}, è­¦å‘Š: {warn_count}")
        logger.info(f"   æ€»èƒ½é‡è®°å½•: {new_count}")
        
        return True
        
    except Exception as e:
        logger.error(f"EvoEF2 è®¡ç®—å¼‚å¸¸: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return False


# ============================================================================
# ä¸»æµç¨‹
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="Phase 0 è‡ªåŠ¨åŒ–ç®¡çº¿")
    parser.add_argument("--skip_wait", action="store_true", 
                        help="è·³è¿‡ç­‰å¾…ä¸‹è½½ï¼Œç›´æ¥å¼€å§‹å¤„ç†")
    parser.add_argument("--skip_preprocess", action="store_true",
                        help="è·³è¿‡é¢„å¤„ç†")
    parser.add_argument("--skip_evoef2", action="store_true",
                        help="è·³è¿‡ EvoEF2 è®¡ç®—")
    parser.add_argument("--sleep_minutes", type=int, default=30,
                        help="ç­‰å¾…é—´éš”ï¼ˆåˆ†é’Ÿï¼‰")
    args = parser.parse_args()
    
    config = DEFAULT_CONFIG.copy()
    config["sleep_minutes"] = args.sleep_minutes
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(config["log_dir"])
    
    logger.info("=" * 60)
    logger.info("Phase 0 è‡ªåŠ¨åŒ–ç®¡çº¿å¯åŠ¨")
    logger.info("=" * 60)
    logger.info(f"é…ç½®:")
    logger.info(f"  - Batch æ–‡ä»¶: {len(config['batch_files'])} ä¸ª")
    logger.info(f"  - åŸå§‹ç›®å½•: {config['raw_dir']}")
    logger.info(f"  - å¤„ç†ç›®å½•: {config['processed_dir']}")
    logger.info(f"  - èƒ½é‡ç¼“å­˜: {config['energy_cache']}")
    logger.info(f"  - ç­‰å¾…é—´éš”: {config['sleep_minutes']} åˆ†é’Ÿ")
    
    # Step 1: ç­‰å¾…ä¸‹è½½å®Œæˆ
    if not args.skip_wait:
        logger.info("\n" + "=" * 40)
        logger.info("Step 1: æ£€æŸ¥ PDB ä¸‹è½½è¿›åº¦")
        logger.info("=" * 40)
        
        if not wait_for_download(
            config["batch_files"],
            config["raw_dir"],
            config["sleep_minutes"],
            logger
        ):
            logger.warning("ä¸‹è½½ç­‰å¾…è¢«ä¸­æ–­ï¼Œé€€å‡º")
            return
    else:
        logger.info("è·³è¿‡ä¸‹è½½ç­‰å¾…æ£€æŸ¥")
    
    # Step 2: é¢„å¤„ç†
    if not args.skip_preprocess:
        logger.info("\n" + "=" * 40)
        logger.info("Step 2: è¿è¡Œ PPI é¢„å¤„ç†")
        logger.info("=" * 40)
        
        if not run_preprocess(
            config["raw_dir"],
            config["processed_dir"],
            logger
        ):
            logger.error("é¢„å¤„ç†å¤±è´¥ï¼Œé€€å‡º")
            return
    else:
        logger.info("è·³è¿‡é¢„å¤„ç†")
    
    # Step 3: EvoEF2 èƒ½é‡è®¡ç®—
    if not args.skip_evoef2:
        logger.info("\n" + "=" * 40)
        logger.info("Step 3: è¿è¡Œ EvoEF2 èƒ½é‡è®¡ç®—")
        logger.info("=" * 40)
        
        if not run_evoef2_batch(
            config["raw_dir"],
            config["energy_cache"],
            logger
        ):
            logger.error("EvoEF2 è®¡ç®—å¤±è´¥")
            return
    else:
        logger.info("è·³è¿‡ EvoEF2 è®¡ç®—")
    
    # å®Œæˆ
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ‰ Phase 0 ç®¡çº¿å®Œæˆï¼")
    logger.info("=" * 60)
    
    # æœ€ç»ˆç»Ÿè®¡
    processed_count = len(get_processed_pairs(config["processed_dir"]))
    energy_count = len(get_computed_energies(config["energy_cache"]))
    
    logger.info(f"æœ€ç»ˆç»Ÿè®¡:")
    logger.info(f"  - å¤„ç†çš„ PPI å¯¹: {processed_count}")
    logger.info(f"  - èƒ½é‡è®°å½•: {energy_count}")
    
    logger.info(f"\nä¸‹ä¸€æ­¥: å¯ä»¥å¼€å§‹ Phase 3A è®­ç»ƒ")
    logger.info(f"  python flowtcr_fold/TCRFold_Light/train_ppi.py ...")


if __name__ == "__main__":
    main()

