# FlowTCR-Fold: Physics-Grounded Generative TCR Design

> **Three-Stage TCR Design Framework**: Scaffold Retrieval â†’ Topology-Aware CDR3Î² Generation â†’ Physics-Grounded Validation

---

## Table of Contents

1. [Project Overview](#1-project-overview)
2. [Core Design Philosophy](#2-core-design-philosophy)
3. [Two-Stage Design Strategy](#3-two-stage-design-strategy)
4. [Core Methodology Claims](#core-methodology-claims-è®ºæ–‡å®šä½) â¬…ï¸ **Paper Positioning**
5. [Master Plan v3.1](#master-plan-v31-flowtcr-fold-execution-frame)
6. [Module Architecture](#4-module-architecture)
7. [Data Infrastructure](#5-data-infrastructure)
8. [Training Workflows](#6-training-workflows)
9. [Inference Pipeline](#7-inference-pipeline)
10. [Code Layout](#8-code-layout)
11. [Quickstart Guide](#9-quickstart-guide)
12. [Legacy Code References](#10-legacy-code-references)
13. [Status & Roadmap](#11-status--roadmap)

---

## 1. Project Overview

### 1.1 Scientific Goal

Design **antigen-specific T Cell Receptors (TCRs)** given a target peptide-MHC (pMHC) complex. This has transformative implications for:
- Cancer immunotherapy (CAR-T, TCR-T)
- Vaccine development
- Autoimmune disease treatment

### 1.2 Technical Challenge

TCR-pMHC recognition is governed by complex sequence-structure interactions:
- **CDR3Î² loop**: Primary determinant of antigen specificity
- **V/J gene scaffolds**: Provide structural framework and MHC compatibility
- **Multi-chain topology**: TCRÎ±/Î² chains interact with pMHC in a coordinated manner

### 1.3 Our Approach

A **Retrieve & Generate** framework that decomposes the problem into two tractable sub-tasks:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: Target pMHC (peptide + MHC allele)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: SCAFFOLD RETRIEVAL                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  Immuno-PLM retrieves Top-K V/J scaffolds (lv, lj, hv, hj)     â”‚
â”‚  that are compatible with the target MHC                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: CDR3Î² GENERATION                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚  FlowTCR-Gen generates CDR3Î² conditioned on pMHC + scaffold    â”‚
â”‚  using Discrete Flow Matching                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: PHYSICS VALIDATION                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  TCRFold-Prophet (S_Ïˆ) + Energy Surrogate (E_Ï†) + MC Refinement â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output: Complete TCR sequence (scaffold + CDR3Î²)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Core Design Philosophy

### 2.1 Hybrid Intelligence

We do not rely solely on data fitting. The system combines:

| Component | Role | Source |
|-----------|------|--------|
| **Discrete Flow Matching** | Global sequence search | FlowTCR-Gen |
| **ESM-2 / Topology Embeddings** | Universal protein semantics | Immuno-PLM |
| **EvoEF2 Energy** | First-principles physics | Physics module |
| **Hierarchical Pair Bias** | TCR-pMHC topology awareness | Legacy psi_model |

### 2.2 Retrieve & Generate Paradigm

**Why not generate scaffolds directly?**

| Challenge | Explanation |
|-----------|-------------|
| Discrete space | V/J genes are categorical (e.g., TRBV19*01), not continuous |
| Combinatorial explosion | VÎ² Ã— JÎ² Ã— VÎ± Ã— JÎ± = hundreds of thousands of combinations |
| Data sparsity | Many combinations appear only a few times in training data |

**Solution**: Retrieve scaffolds from a pre-computed bank, then generate CDR3Î².

### 2.3 Safe Contrastive Learning

To avoid "false negative" issues in InfoNCE training:

- **Batch Random Negatives**: Use other samples in the same batch as negatives
- **No explicit hard negative mining from database**: Avoids accidentally marking true binders as negatives
- **Synthetic negatives (optional)**: Mutate anchor positions to create guaranteed non-binders

---

## 3. Two-Stage Design Strategy

### 3.1 Stage 1: Scaffold Retrieval

**Objective**: Find V/J gene combinations compatible with the target MHC.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SCAFFOLD RETRIEVAL                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Input:  Target pMHC sequence                                â”‚
â”‚                                                              â”‚
â”‚  Model:  Immuno-PLM (InfoNCE encoder)                        â”‚
â”‚                                                              â”‚
â”‚  Bank:   Pre-computed scaffold embeddings                    â”‚
â”‚          - Key: (h_v, h_j, l_v, l_j) gene combination        â”‚
â”‚          - Value: Germline amino acid sequences              â”‚
â”‚          - Vector: Immuno-PLM embeddings                     â”‚
â”‚                                                              â”‚
â”‚  Method:                                                     â”‚
â”‚    1. Encode pMHC with Immuno-PLM                            â”‚
â”‚    2. Compute cosine similarity with scaffold bank           â”‚
â”‚    3. Retrieve Top-K scaffolds                               â”‚
â”‚                                                              â”‚
â”‚  Output: Top-K scaffold sequences                            â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Physical Interpretation**: Select V genes whose structural framework is compatible with the target MHC's binding groove.

### 3.2 Stage 2: CDR3Î² Generation

**Objective**: Generate CDR3Î² loop that binds the target peptide.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CDR3Î² GENERATION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Input:  pMHC + Scaffold (from Stage 1)                      â”‚
â”‚                                                              â”‚
â”‚  Model:  FlowTCR-Gen (Conditional Flow Matching)             â”‚
â”‚                                                              â”‚
â”‚  Conditioning:                                               â”‚
â”‚    - pMHC embedding (from Immuno-PLM)                        â”‚
â”‚    - Scaffold embedding (from Immuno-PLM)                    â”‚
â”‚    - (Optional) TM-align PSSM for structural prior           â”‚
â”‚    - (Optional) Geometry summary from TCRFold-Light          â”‚
â”‚                                                              â”‚
â”‚  Method:                                                     â”‚
â”‚    - Dirichlet Flow Matching on amino acid simplex           â”‚
â”‚    - Vector field prediction: v_Î¸(x_t, t, cond)              â”‚
â”‚    - Loss: ||v_Î¸ - (y - x_0)||Â²                              â”‚
â”‚                                                              â”‚
â”‚  Output: CDR3Î² sequence candidates                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 Stage 3: Physics Validation (Required)

**Objective**: Validate structural plausibility and energetic feasibility of generated TCRs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHYSICS VALIDATION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Input:  CDR3Î² candidates + Scaffold + pMHC                  â”‚
â”‚                                                              â”‚
â”‚  Model:  TCRFold-Prophet (Evoformer-Single + IPA)            â”‚
â”‚                                                              â”‚
â”‚  ğŸ”´ Must Have:                                               â”‚
â”‚    - S_Ïˆ: Structure predictor (PPI pretrained)               â”‚
â”‚    - E_Ï†: Energy surrogate (EvoEF2-NN)                       â”‚
â”‚    - Post-hoc screening: Flow â†’ S_Ïˆ â†’ E_Ï† ranking            â”‚
â”‚                                                              â”‚
â”‚  ğŸŸ¡ Should Have:                                             â”‚
â”‚    - Offline MC refinement with E_Ï† guidance                 â”‚
â”‚                                                              â”‚
â”‚  ğŸŸ¢ Exploratory:                                             â”‚
â”‚    - Gradient guidance in Flow ODE                           â”‚
â”‚    - MC samples for self-play training                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Core Methodology Claims (è®ºæ–‡å®šä½)

### Primary Contribution: Topology-Aware Flow Matching for CDR3Î² Generation

**FlowTCR-Gen** is the central innovation of this work, featuring:

| Component | Description | Innovation |
|-----------|-------------|------------|
| **Collapse Token (Ïˆ)** | Learnable global observer that aggregates information across regions | Enables cross-region attention without explicit pairwise enumeration |
| **Hierarchical Pair Embeddings** | 7-level topology encoding (Ïˆâ†”region, intra-region, CDR3â†”peptide, CDR3â†”MHC, etc.) | Injects TCR-pMHC structural priors into the embedding space |
| **Dirichlet Flow Matching** | Continuous-time generative model on the amino acid simplex | Supports smooth interpolation and CFG-based conditional control |

**Key Claim**: By combining structural topology priors with discrete flow matching, FlowTCR-Gen generates CDR3Î² sequences that are both diverse and structurally plausible, outperforming autoregressive and VAE baselines.

### Supporting Contribution: Physics-Grounded Validation

The physics module (TCRFold-Prophet + EvoEF2) serves as **independent validation** rather than the main innovation:

| Purpose | Method | Role in Paper |
|---------|--------|---------------|
| Structural plausibility | TCRFold-Prophet (Evoformer-Single + IPA) | Demonstrates generated sequences fold into valid TCR-pMHC structures |
| Energetic feasibility | E_Ï† (EvoEF2-NN surrogate) | Shows binding energy distribution matches natural TCRs |
| Controllable refinement | Monte Carlo with E_Ï† guidance | Optional post-hoc optimization for best candidates |

**Key Claim**: Generated TCRs are not just statistically similar to training data, but are physically realizable (low clash, favorable binding energy).

---

## Master Plan v3.1 (FlowTCR-Fold Execution Frame)

- Goal: given a target pMHC (peptide + MHC allele), Stage 1 outputs biologically reasonable V/J scaffold priors, Stage 2 generates diverse CDR3Î² on chosen scaffolds, Stage 3 folds TCRâ€“pMHC and scores with geometry + physics. Stay within this frame for iteration.
- Practical vs exploratory: Practical = minimal paper-ready loop; Exploratory = optional guidance/decoys that must not block the mainline.

### Stage 1 â€” Immuno-PLM (Scaffold Prior)
- Objective: model p(V,J | MHC, peptide) with MHC as strong signal, peptide as weak refinement; CDR3Î² not fed as input (analysis only).
- Backbone: `esm2_t33_650M_UR50D` + LoRA (rank 16, alpha 32 on Q/K/V/FFN); prepend an allele embedding token; input `<ALLELE_EMB> MHC_seq Peptide_seq [SEP â€¦]`.
- Dual supervision:
  - Multi-positive InfoNCE on sequences: pMHC embedding vs HV/HJ/LV/LJ sequences with two grouping masks (MHC-only main, pMHC auxiliary weight Î»_pmhcâ‰ˆ0.3); missing LV/LJ masked out.
  - Multi-label BCE on gene IDs: group by MHC (primary) and optionally pMHC (secondary weight); pos_weight/focal to handle long tails.
- Metrics: Top-K recall per group (MHC + pMHC) and KL(p_emp || p_model) vs (1) frequency baseline and (2) MHC-only model.

### Stage 2 â€” FlowTCR-Gen (CDR3Î² Generator)

**Objective**: Topology-aware discrete flow generation conditioned on pMHC + scaffold.

**Legacy Reuse**:
- psi_model Collapse token + hierarchical pair embeddings
- Evoformer backbone over concatenated sequence
- Pair IDs explicitly mark CDR3â†”peptide and CDR3â†”MHC interactions

**Flow Head**:
- Dirichlet flow matching on CDR3Î² (x0 = uniform Dirichlet, x1 = one-hot target)
- Loss = MSE(v_pred, v_true) + Î»_entÂ·collapse-entropy + Î»_profÂ·profile reg
- CFG supported (p=0.1 drop cond during training; inference weight w)
- Keep a "model score" hook (flow cost / collapse scalar) for hybrid MC energy

#### Stage 2 Scope Tiers

| Tier | Component | Description | Paper Status |
|------|-----------|-------------|--------------|
| **ğŸ”´ Must Have** | Dirichlet Flow Matching | æ ¸å¿ƒç”Ÿæˆæ¨¡å— + MSE loss | Required |
| **ğŸ”´ Must Have** | Collapse + Hierarchical Pairs | æ‹“æ‰‘æ„ŸçŸ¥ conditioning encoder | Required (main claim) |
| **ğŸ”´ Must Have** | CFG (Classifier-Free Guidance) | p=0.1 drop, w tunable | Required for controllability |
| **ğŸŸ¡ Should Have** | Model Score Hook | Export flow cost for hybrid MC | Recommended |
| **ğŸŸ¢ Exploratory** | Physics Gradient in ODE | `v_Î¸ - wâˆ‡E_Ï†` at sparse steps | Optional, depends on Stage 3 |

### Stage 3 â€” TCRFold-Prophet (Structure + Energy)

**Architecture**:
- Trunk: Evoformer-Single + IPA structure head
- Energy head: E_Ï† as EvoEF2-NN surrogate

**Data**:
- A) General PPI (~50k) for trunk/energy pretrain with EvoEF2 labels
- B) TCR3d/STCRDab for TCR-specific finetune

**Phases**:
- 3A: trunk + struct head on PPI (FAPE + dist/contact)
- 3B: energy head (+ last trunk blocks) to fit EvoEF2, with decoy/noisy structures optional
- 3C: TCR-specific finetune for both heads; target â‰¥0.7 Pearson/Spearman vs EvoEF2 on TCRs

#### Stage 3 Scope Tiers (è®ºæ–‡å¿…éœ€ vs å¯é€‰)

| Tier | Component | Description | Paper Status |
|------|-----------|-------------|--------------|
| **ğŸ”´ Must Have** | S_Ïˆ (Structure Predictor) | General PPI é¢„è®­ç»ƒçš„æŠ˜å ç½‘ç»œ | Required for validation |
| **ğŸ”´ Must Have** | E_Ï† (Energy Surrogate) | åŸºäº PPI + TCR-pMHC çš„ EvoEF2-NN | Required for scoring |
| **ğŸ”´ Must Have** | Post-hoc Screening | Flow â†’ S_Ïˆ â†’ E_Ï† çš„åéªŒç­›é€‰ä¸æ’åº | Required for pipeline |
| **ğŸŸ¡ Should Have** | Offline MC Refinement | åŸºäº E_Ï† çš„ Monte Carlo åºåˆ—ä¼˜åŒ– | Strongly recommended |
| **ğŸŸ¢ Exploratory** | Gradient Guidance in Flow ODE | `x_{t+Î”t} = x_t + (v_Î¸ - wâˆ‡E_Ï†)Î”t` | Optional, high compute |
| **ğŸŸ¢ Exploratory** | MC-to-Training Loop | MC ç”Ÿæˆæ ·æœ¬ç”¨äºäºŒæ¬¡è®­ç»ƒ (self-play) | Future work |

**Rationale**: The Must Have tier provides independent evidence that generated sequences are physically valid. The Should Have tier (MC refinement) is straightforward to implement given E_Ï† and significantly improves best-case results. Exploratory items are computationally expensive and should not block the main paper.

### Execution Timeline
- T1: finalize Stage 1 grouping and loss wiring (dual InfoNCE + BCE); run training with Top-K/KL vs baselines.
- T2: baseline FlowTCR-Gen with collapse/pair reuse + Dirichlet flow + CFG; validate recon/diversity; log model-score hook.
- T3: Stage 3 phases: 3A/3B on PPI (structure then energy), then 3C TCR finetune; export E_Ï† for fast scoring.
- T4: Integration: Flow samples â†’ TCRFold-Prophet + E_Ï† screen â†’ MC (E_Ï† or hybrid) â†’ EvoEF2 final check; later explore guided flow with âˆ‡E_Ï†.

### Module / Legacy / New-Tech Matrix
| Stage | Task | Model Backbone | Legacy Usage | New Tech |
|-------|------|----------------|--------------|----------|
| 1 | Scaffold sampling (V/J) | ESM-2 650M + LoRA | Avoid heavy Evoformer here | Multi-positive InfoNCE + causal/BCE heads |
| 2 | CDR3Î² generation | psi_model Evoformer | âœ… Collapse token + hierarchical pairs | Dirichlet flow head + CFG + grad-guidance hook |
| 3 | Validation (structure + energy) | TCRFold-Light / Prophet | âœ… Evoformer trunk | EvoEF2-NN surrogate + PDB/TCR3d + MC |

## Pipeline v3.1 Detail (Practical vs Exploratory)

### Stage 1 â€” Immuno-PLM (Scaffold Prior)
- Role: scaffold prior; model p(V,J | MHC, peptide). MHC = strong signal, peptide = weak refinement; CDR3Î² not used as input (analysis only).
- Inputs: prepend allele embedding token; ESM encodes mhc_sequence+peptide. HV/HJ/LV/LJ sequences feed InfoNCE; HV/HJ/LV/LJ ids feed multi-label BCE. CDR3Î² only for stats.
- Dual channels:
  - Sequence InfoNCE with multi-positive masks: main grouping by MHC, auxiliary by (peptide,MHC) weighted Î»_pmhcâ‰ˆ0.3; missing LV/LJ masked; pos_mask precomputed offline.
  - Multi-label BCE on gene ids: grouped by MHC (primary) + optional pMHC weak weight; pos_weight/focal for long tails; allele cold-start fallback to seq-only/NN.
- Loss: L = L_NCE_MHC + Î»_pmhcÂ·L_NCE_pMHC + Î»_bceÂ·L_BCE (Î»_bceâ‰ˆ0.2 start). Metrics: Top-K per group, KL(p_emp||p_model) vs frequency & MHC-only baselines. Target R@10 â‰ˆ20â€“40% (v1 ~1%), KL(model) < KL(baseline).

### Stage 2 â€” FlowTCR-Gen (CDR3Î² Generator)
- Input layout: [Ïˆ, CDR3Î², peptide, MHC, scaffold]; pair IDs use 7-level hierarchy (psi_model) marking CDR3â†”peptide/MHC.
- Backbone reuse: CollapseAwareEmbedding + SequenceProfileEvoformer (MSA-free) + hierarchical pairs. Long-seq caution: truncate/clip MHC or chunked attention.
- x_t injection: use `x_proj(x_t) + pos_emb` for CDR3 region (replace one-hot). Evoformer runs on full concatenated sequence.
- Flow head: Dirichlet flow matching (x0 uniform Dirichlet, x1 one-hot); loss = MSE(v_pred,v_true) + Î»_entÂ·collapse-entropy + Î»_profÂ·profile reg; decide vocab 20/21 and log.
- CFG: train p=0.1 cond drop; infer v_uncond + w(v_condâˆ’v_uncond), w tunable. Keep model-score hook (flow cost / collapse scalar) for hybrid MC energy.
- Practical: flow loss + regs + CFG; physics post-hoc. Exploratory: sparse âˆ‡E_Ï† guidance inside ODE; grad-informed MC proposals.

### Stage 3 â€” TCRFold-Prophet (Structure + Energy)
- Trunk/heads: Evoformer-Single + IPA struct head; energy head E_Ï† (EvoEF2 surrogate, pair-pooling or lightweight GVP).
- Data: A=general PPI (~50k) with EvoEF2; B=TCR3d/STCRDab (~500â€“1k) for TCR finetune.
- Phases: 3A struct pretrain (FAPE + dist/contact), 3B energy fit (MSE to EvoEF2, decoys/noisy structures encouraged), 3C TCR finetune both heads; target corr â‰¥0.7 on TCR.
- Integration: MC with E_Ï† or hybrid Î±Â·E_Ï†+Î²Â·model score; guided flow remains exploratory (apply every N ODE steps or only top-N samples).

### End-to-End Loop
1) Stage1 â†’ scaffold bank/top-K priors.  
2) Stage2 â†’ CDR3Î² samples (CFG) with model-score.  
3) Stage3 â†’ TCRFold-Prophet struct + E_Ï† screen â†’ MC refine (E_Ï† or hybrid) â†’ final EvoEF2 check.  
Exploratory: guided flow with âˆ‡E_Ï† and grad-informed MC proposals.

## Plan Review v3.1 (Feasibility Snapshot)

### Overall
| ç»´åº¦ | è¯„åˆ† | è¯„ä»· |
|------|------|------|
| æ¦‚å¿µå®Œæ•´æ€§ | â­â­â­â­â­ | ä¸‰ä¸ª Stage åˆ†å·¥æ˜ç¡®ï¼Œé€»è¾‘è‡ªæ´½ |
| æŠ€æœ¯å¯è¡Œæ€§ | â­â­â­â­â˜† | å¤§éƒ¨åˆ†å¯è¡Œï¼Œå°‘æ•°éœ€è°ƒæ•´ |
| å®ç°å¤æ‚åº¦ | â­â­â­â˜†â˜† | ä¸­é«˜å¤æ‚åº¦ï¼Œéœ€è¦æ’æœŸ |
| åˆ›æ–°æ€§ | â­â­â­â­â­ | å¤šå¤„åˆ›æ–°ç‚¹ï¼Œè®ºæ–‡ä»·å€¼é«˜ |
| Practical/Exploratory åˆ’åˆ† | â­â­â­â­â­ | ä¸»çº¿æ¸…æ™°ï¼Œæ¢ç´¢ä¸é˜»å¡ |

ç»“è®ºï¼šâœ… é«˜åº¦å¯è¡Œï¼ŒæŒ‰æ­¤è®¡åˆ’æ‰§è¡Œã€‚

### Stage 1
- å¯è¡Œï¼šESM-2+LoRA(rank16)ã€MHC+allele embeddingã€åŒå±‚ InfoNCEï¼ˆMHC ä¸» + pMHC è¾… Î»â‰ˆ0.3ï¼‰ã€å¤šæ ‡ç­¾ BCEã€Top-K/KLã€MHC-only baselineã€‚
- æ³¨æ„ï¼šæœªè§ allele å†·å¯åŠ¨ï¼ˆseq-only æˆ– NN fallbackï¼‰ï¼›pos_mask é¢„è®¡ç®—ï¼›Î»_bce åˆå€¼ 0.2 åç»­è°ƒã€‚
- é¢„æœŸï¼šR@10 â‰ˆ20â€“40%ï¼ˆç° 1.1%ï¼‰ï¼›KL(model) < KL(baseline)ã€‚

### Stage 2
- å¯è¡Œï¼šCollapseAwareEmbeddingã€SequenceProfileEvoformerã€7-level pairsã€Dirichlet Flowã€CFG(p=0.1)ã€entropy/profile æ­£åˆ™ã€‚
- è°ƒæ•´ï¼šé•¿åºåˆ—éœ€æˆªæ–­ MHC æˆ– chunked attentionï¼›x_t ç”¨ `x_proj(x_t)+pos_emb`; Flow å¤´è¾“å‡º 20/21 éœ€å®šã€‚
- ä»£ç æ”¹åŠ¨ï¼šåœ¨ psi_model å¢ flow åˆ†æ”¯/å¤´ï¼›æ–°å¢ `FlowTCR_Gen/flow_gen.py`ï¼ˆFlowMatchingModelã€flow_matching_lossã€ODE sampleï¼‰ã€‚

### Stage 3
- å¯è¡Œï¼š3A PPI é¢„è®­ï¼Œ3B EvoEF2 èƒ½é‡å›å½’ï¼Œ3C TCR å¾®è°ƒï¼›E_Ï† surrogate + MCï¼ˆå¤ç”¨ psiMonteCarloSamplerï¼‰ã€‚
- èµ„æºï¼š3A 50k PPI 3â€“7 å¤©@4Ã—A100(~40GB)ï¼›3B 1â€“2 å¤©(~20GB)ï¼›3C å‡ å°æ—¶(~16GB)ã€‚
- é£é™©ï¼šE_Ï† ç›¸å…³æ€§<0.7 â†’ åŠ  decoy/ranking lossï¼›Guided ODE è®¡ç®—å¤§ â†’ ç•™åœ¨ Exploratoryã€‚

### Execution Timeline (12â€“16 wks, condensed)
- W1-2: Stage1 Practicalï¼ˆdual InfoNCE/BCE+allele embï¼›Milestone R@10>20%, KL<baselineï¼‰
- W3-5: Stage2 Practicalï¼ˆFlowTCRGen refactor+flow_loss+ODE+CFGï¼›Milestone recovery>30%, ppl<10ï¼‰
- W6-8: Stage3 3A/3Bï¼ˆPDB+EvoEF2 labelsï¼›corr>0.6ï¼‰
- W9-10: Stage3 3C + MC é›†æˆï¼ˆcorr>0.7 on TCRï¼‰
- W11-12: End-to-end eval + paperï¼›W13+: Exploratoryï¼ˆguided ODE, grad-informed MC, self-playï¼‰

### Data/Checkpoint Hygiene & Ablations
- Data: `trn_v1.jsonl` (raw), `trn_v2.jsonl` (clean), `scaffold_bank_v1.json`, `energy_labels/` (EvoEF2 cache).
- Checkpoints: `stage1_v1/`, `stage1_v2/`, `stage2_v1/`, `stage3_phase_a/`, `stage3_phase_b/`, `stage3_phase_c/`, `pipeline_v1/`.
- Ablations: Stage1 MHC-only vs pMHC; Stage2 Â±collapse, Â±hier pairs; Stage3 E_Ï† vs EvoEF2 ranking.

### Immediate Starts
1) Stage1 dual InfoNCE + multi-label BCE + gene-name cleanup  
2) Stage2 psiCLMâ†’FlowTCRGen refactorï¼ˆx_t æ³¨å…¥ + flow headï¼‰  
3) PDB ä¸‹è½½ä¸ EvoEF2 æ‰¹å¤„ç†è„šæœ¬

---
## 4. Module Architecture

### 4.1 Immuno-PLM (Scaffold Prior) â€” Status: ğŸ”„ **In Progress**

**Role**: Model p(V, J | MHC, peptide) â€” MHC as strong signal, peptide as weak refinement.

**Core Design**: ESM-2 + LoRA backbone with dual supervision (multi-positive InfoNCE + multi-label BCE).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Immuno-PLM v3.1 Architecture                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Input: <ALLELE_EMB> + MHC_seq + Peptide_seq + [SEP]           â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    ESM-2 (esm2_t33_650M_UR50D) + LoRA (rank16, Î±=32)      â”‚ â”‚
â”‚  â”‚    + Allele Embedding Table (HLA-A*02:01 â†’ vector)        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚               z_pmhc [B, 256] (CLS pooling + projection)        â”‚
â”‚                             â”‚                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â–¼              â–¼              â–¼                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚     â”‚ Multi-pos   â”‚  â”‚ Multi-pos â”‚  â”‚ Multi-labelâ”‚             â”‚
â”‚     â”‚ InfoNCE     â”‚  â”‚ InfoNCE   â”‚  â”‚ BCE        â”‚             â”‚
â”‚     â”‚ (MHC group) â”‚  â”‚ (pMHC grp)â”‚  â”‚ (gene IDs) â”‚             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚            â”‚               â”‚               â”‚                    â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚     L = L_NCE_MHC + Î»_pmhcÂ·L_NCE_pMHC + Î»_bceÂ·L_BCE            â”‚
â”‚         (Î»_pmhcâ‰ˆ0.3, Î»_bceâ‰ˆ0.2)                                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Choices**:
- **Dual-group InfoNCE**: MHC-only grouping (main) + pMHC grouping (auxiliary Î»â‰ˆ0.3)
- **Multi-label BCE**: V/J gene IDs as multi-hot targets with pos_weight/focal
- **Metrics**: Top-K recall + KL(p_emp || p_model) vs frequency baseline

**Training**:
```bash
python -m flowtcr_fold.Immuno_PLM.train_scaffold_retrieval \
    --data flowtcr_fold/data/trn.jsonl \
    --use_esm --use_lora --lora_rank 16 \
    --epochs 100 --batch_size 16
```

### 4.2 FlowTCR-Gen (CDR3Î² Generator) â€” Status: ğŸ”„ **40% Complete**

**Role**: Topology-aware discrete flow generation conditioned on pMHC + scaffold.

**Core Innovation**: Reuses `psi_model` components for rich conditioning.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   FlowTCR-Gen v3.1 Architecture                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Input: [Ïˆ, CDR3Î²(x_t), peptide, MHC, HV, HJ, LV, LJ]          â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    CollapseAwareEmbedding (from psi_model)                â”‚ â”‚
â”‚  â”‚    + Hierarchical Pair IDs (7 levels)                     â”‚ â”‚
â”‚  â”‚    + Region-specific adaptive weights                     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    SequenceProfileEvoformer (from psi_model)              â”‚ â”‚
â”‚  â”‚    + Time embedding injection                             â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Flow Head: Linear(s_dim â†’ 20/21)                       â”‚ â”‚
â”‚  â”‚    Output: v_pred for CDR3Î² region only                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  Loss = MSE(v_pred, v_true) + Î»_entÂ·collapse_entropy           â”‚
â”‚       + Î»_profÂ·profile_reg                                     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Features**:
- **Collapse Token (Ïˆ)**: Global observer aggregating cross-region information
- **Hierarchical Pairs**: 7-level topology encoding CDR3â†”peptide, CDR3â†”MHC interactions
- **Dirichlet Flow**: x0 = uniform Dirichlet, x1 = one-hot target
- **CFG Support**: p=0.1 drop conditioning during training; tunable w at inference

**Training**:
```bash
python -m flowtcr_fold.FlowTCR_Gen.train_flow \
    --data flowtcr_fold/data/trn.jsonl \
    --epochs 100 --batch_size 32 --lr 1e-4
```

### 4.3 TCRFold-Prophet (Structure + Energy) â€” Status: ğŸ”„ **75% Complete**

**Role**: Validate structural plausibility and predict binding energy for candidate filtering.

**Architecture**: Evoformer-Single + IPA structure head + Energy surrogate E_Ï†

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TCRFold-Prophet Architecture                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Input: TCR + pMHC sequences (concatenated)                     â”‚
â”‚       â”‚                                                         â”‚
â”‚       â–¼                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    ESM-2 per-residue features + chain type embedding      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                   â”‚
â”‚                             â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Evoformer-Single Trunk (N layers)                      â”‚ â”‚
â”‚  â”‚    - Triangle attention + pair update + single attention  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                             â”‚                                   â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚              â–¼              â–¼              â–¼                    â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚     â”‚ S_Ïˆ: IPA    â”‚  â”‚ Distance  â”‚  â”‚ E_Ï†: Energyâ”‚             â”‚
â”‚     â”‚ Struct Head â”‚  â”‚ + Contact â”‚  â”‚ Surrogate  â”‚             â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Training Phases**:
| Phase | Data | Objective | Target |
|-------|------|-----------|--------|
| 3A | General PPI (~50k) | FAPE + dist/contact | Trunk pretraining |
| 3B | PPI + EvoEF2 labels | MSE(E_Ï†, E_EvoEF2) | Energy surrogate |
| 3C | TCR3d + STCRDab | Finetune all heads | â‰¥0.7 corr with EvoEF2 |

**Scope Tiers**:
- ğŸ”´ **Must**: S_Ïˆ + E_Ï† + post-hoc screening
- ğŸŸ¡ **Should**: Offline MC refinement with E_Ï†
- ğŸŸ¢ **Exploratory**: Gradient guidance in Flow ODE

---

## 5. Data Infrastructure

### 5.1 Data Sources

| Dataset | Size | Fields | Usage |
|---------|------|--------|-------|
| **Paired TCR-pMHC** (trn.csv) | 200K+ | peptide, mhc, cdr3_b, h_v, h_j, l_v, l_j | Scaffold bank, Immuno-PLM, FlowTCR-Gen |
| **TCRdb CDR3Î²** | Large | cdr3_b only | (Optional) Flow pretraining |
| **STCRDab / TCR3d** | ~500 | PDB structures | TCRFold-Light training |

### 5.2 Data Fields

```
Required:
â”œâ”€â”€ peptide    : Antigenic peptide sequence (8-15 aa)
â”œâ”€â”€ mhc        : MHC allele name or sequence
â””â”€â”€ cdr3_b     : CDR3Î² sequence (target for generation)

Optional:
â”œâ”€â”€ h_v        : Heavy chain V gene
â”œâ”€â”€ h_j        : Heavy chain J gene
â”œâ”€â”€ l_v        : Light chain V gene (alpha)
â””â”€â”€ l_j        : Light chain J gene (alpha)
```

### 5.3 Scaffold Bank Construction

```python
# Extract unique V/J combinations from paired data
import pandas as pd

df = pd.read_csv("data/trn.csv")

# Group by V/J genes
scaffold_bank = df.groupby(['h_v', 'h_j', 'l_v', 'l_j']).agg({
    'peptide': 'first',  # Representative peptide
    'mhc': 'first',      # Representative MHC
    'cdr3_b': 'count'    # Frequency
}).reset_index()

scaffold_bank.columns = ['h_v', 'h_j', 'l_v', 'l_j', 'rep_peptide', 'rep_mhc', 'count']
scaffold_bank.to_csv("data/scaffold_bank.csv", index=False)

print(f"Unique scaffolds: {len(scaffold_bank)}")
```

### 5.4 Hard Negative Strategies

| Type | Strategy | Safety |
|------|----------|--------|
| **Batch Random** | Other samples in batch as negatives | âœ… Safe |
| **Peptide Decoy** | Same MHC, similar peptide (60-90% identity) | âš ï¸ Moderate |
| **CDR3 Mutant** | Same pMHC, 2-3 point mutations in CDR3 | âš ï¸ Moderate |
| **Synthetic** | Mutate anchor positions to opposite charge | âœ… Safe |

---

## 6. Training Workflows

### 6.1 Scaffold Prior Training (Immuno-PLM)

**Objective**: Model p(V, J | MHC, peptide) with dual supervision.

```bash
# Production mode (ESM-2 + LoRA + dual supervision)
python -m flowtcr_fold.Immuno_PLM.train_scaffold_retrieval \
    --data flowtcr_fold/data/trn.jsonl \
    --use_esm --use_lora --lora_rank 16 \
    --epochs 100 --batch_size 16 \
    --lambda_pmhc 0.3 --lambda_bce 0.2
```

**Loss Function** (Dual-Group InfoNCE + Multi-label BCE):

```python
# Multi-positive InfoNCE with dual grouping
loss_nce_mhc = multi_pos_infonce(z_pmhc, z_hv, pos_mask_mhc) + ...  # MHC grouping
loss_nce_pmhc = multi_pos_infonce(z_pmhc, z_hv, pos_mask_pmhc) + ... # pMHC grouping

# Multi-label BCE for gene ID prediction
loss_bce = BCEWithLogits(logits_hv, multi_hot_hv, pos_weight=class_weights) + ...

# Total (Î»_pmhcâ‰ˆ0.3, Î»_bceâ‰ˆ0.2)
loss = loss_nce_mhc + Î»_pmhc * loss_nce_pmhc + Î»_bce * loss_bce
```

### 6.2 FlowTCR-Gen Training

**Objective**: Learn to generate CDR3Î² given pMHC + scaffold.

```bash
python flowtcr_fold/FlowTCR_Gen/train_flow.py \
    --data data/trn.csv \
    --epochs 100 \
    --batch_size 32 \
    --lr 1e-4 \
    --out_dir checkpoints/flow
```

**Loss Function** (Flow Matching):

```python
def flow_matching_loss(model, x_0, y, condition):
    # x_0: uniform noise [B, L, vocab]
    # y: one-hot target [B, L, vocab]
    t = torch.rand(x_0.size(0), 1, 1, device=x_0.device)
    x_t = (1 - t) * x_0 + t * y  # Interpolant
    v_target = y - x_0           # Target vector field
    v_pred = model(x_t, t, condition)
    return F.mse_loss(v_pred, v_target)
```

### 6.3 TCRFold-Prophet Training (3-Phase)

**Objective**: Learn structure prediction + energy surrogate for physics validation.

```bash
# Phase 3A: General PPI structure pretraining
python -m flowtcr_fold.TCRFold_Light.train_ppi_impl \
    --pdb_dir data/pdb_structures \
    --epochs 100 --batch_size 4 \
    --out_dir checkpoints/stage3_phase_a

# Phase 3B: Energy surrogate fitting
python -m flowtcr_fold.TCRFold_Light.train_energy_surrogate \
    --pdb_dir data/pdb_structures \
    --evoef2_cache data/energy_labels \
    --epochs 50 --batch_size 8 \
    --out_dir checkpoints/stage3_phase_b

# Phase 3C: TCR-specific finetuning
python -m flowtcr_fold.TCRFold_Light.train_tcr_impl \
    --tcr_pdb_dir data/tcr_structures \
    --pretrain_ckpt checkpoints/stage3_phase_b/best.pt \
    --epochs 50 --batch_size 4 \
    --out_dir checkpoints/stage3_phase_c
```

**Loss Functions by Phase**:

```python
# Phase 3A: Structure losses
L_3A = L_FAPE + 0.3 * L_dist + 0.3 * L_contact

# Phase 3B: Add energy surrogate
L_3B = L_FAPE + 0.3 * L_dist + L_energy  # MSE(E_Ï†, E_EvoEF2)

# Phase 3C: TCR-specific (all heads)
L_3C = L_FAPE + 0.3 * L_dist + 0.3 * L_contact + L_energy
```

### 6.4 Training Preferences

| Setting | Value | Location |
|---------|-------|----------|
| Checkpoint frequency | Every 50 epochs | `common/utils.py` |
| Early stopping patience | 100 epochs | `common/utils.py` |
| Gradient clipping | max_norm=1.0 | Training scripts |

---

## 7. Inference Pipeline

### 7.1 Complete Workflow

```python
from flowtcr_fold.Immuno_PLM import ImmunoPLM
from flowtcr_fold.FlowTCR_Gen import FlowMatchingModel
from flowtcr_fold.TCRFold_Light import TCRFoldLight
from flowtcr_fold.physics import TCRStructureOptimizer

# 1. Load models
plm = ImmunoPLM.load("checkpoints/plm/immuno_plm.pt")
flow = FlowMatchingModel.load("checkpoints/flow/flow_gen.pt")
critic = TCRFoldLight.load("checkpoints/tcrfold/tcrfold_light.pt")
optimizer = TCRStructureOptimizer()

# 2. Encode target pMHC
target_pmhc = {"peptide": "GILGFVFTL", "mhc": "HLA-A*02:01"}
pmhc_emb = plm.encode_pmhc(target_pmhc)

# 3. Stage 1: Retrieve Top-K scaffolds
scaffold_bank = load_scaffold_bank("data/scaffold_bank.csv")
scaffold_embs = plm.encode_scaffolds(scaffold_bank)
similarities = pmhc_emb @ scaffold_embs.T
top_k_indices = similarities.topk(10).indices
top_scaffolds = [scaffold_bank[i] for i in top_k_indices]

# 4. Stage 2: Generate CDR3Î² for each scaffold
candidates = []
for scaffold in top_scaffolds:
    scaffold_emb = plm.encode_scaffold(scaffold)
    condition = torch.cat([pmhc_emb, scaffold_emb], dim=-1)
    
    # Sample multiple CDR3Î² sequences
    for _ in range(100):
        cdr3b = flow.sample(condition)
        candidates.append({
            "scaffold": scaffold,
            "cdr3b": cdr3b,
            "condition": condition
        })

# 5. Stage 3: Critique and rank
scored_candidates = []
for cand in candidates:
    # TCRFold-Light scoring
    score = critic.score(cand["scaffold"], cand["cdr3b"])
    cand["tcrfold_score"] = score
    
    # (Optional) EvoEF2 refinement
    if score > threshold:
        energy = optimizer.compute_binding_energy(cand)
        cand["energy"] = energy
    
    scored_candidates.append(cand)

# 6. Final ranking
scored_candidates.sort(key=lambda x: x.get("energy", x["tcrfold_score"]))
top_designs = scored_candidates[:10]
```

### 7.2 Command-Line Interface

```bash
# Run full pipeline
python flowtcr_fold/FlowTCR_Gen/pipeline_impl.py \
    --peptide "GILGFVFTL" \
    --mhc "HLA-A*02:01" \
    --top_k_scaffolds 10 \
    --samples_per_scaffold 100 \
    --output results/designs.csv
```

---

## 8. Code Layout

```
flowtcr_fold/
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ TODO.md                             # Task tracking
â”œâ”€â”€ EVOEF2_INTEGRATION.md               # EvoEF2 setup guide
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ USER_MANUAL.md                  # User guide (ä¸­æ–‡)
â”‚   â”œâ”€â”€ Plan_v2.0.md                    # Design plan v2.0 (ä¸­æ–‡)
â”‚   â”œâ”€â”€ initial_plan.md                 # Original methodology
â”‚   â””â”€â”€ initial_plan_update.md          # Updated methodology
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ dataset.py                      # FlowDataset with triplet sampling
â”‚   â”œâ”€â”€ tokenizer.py                    # BasicTokenizer / ESM tokenizer
â”‚   â””â”€â”€ convert_csv_to_jsonl.py         # Data preprocessing
â”‚
â”œâ”€â”€ common/
â”‚   â””â”€â”€ utils.py                        # Checkpointing, early stopping
â”‚
â”œâ”€â”€ Immuno_PLM/
â”‚   â”œâ”€â”€ immuno_plm.py                   # ImmunoPLM model
â”‚   â”œâ”€â”€ train_plm.py                    # Training script
â”‚   â””â”€â”€ eval_plm.py                     # Evaluation script
â”‚
â”œâ”€â”€ FlowTCR_Gen/
â”‚   â”œâ”€â”€ flow_gen.py                     # FlowMatchingModel
â”‚   â”œâ”€â”€ train_flow.py                   # Training script
â”‚   â””â”€â”€ pipeline_impl.py                # Full inference pipeline
â”‚
â”œâ”€â”€ TCRFold_Light/
â”‚   â”œâ”€â”€ tcrfold_light.py                # TCRFoldLight model
â”‚   â”œâ”€â”€ train_ppi_impl.py               # PPI pretraining
â”‚   â”œâ”€â”€ train_tcr_impl.py               # TCR finetuning
â”‚   â””â”€â”€ train_with_energy.py            # Energy-supervised training
â”‚
â”œâ”€â”€ physics/
â”‚   â”œâ”€â”€ evoef_runner.py                 # EvoEF2 Python wrapper
â”‚   â”œâ”€â”€ energy_dataset.py               # Energy-labeled dataset
â”‚   â”œâ”€â”€ test_evoef.py                   # EvoEF2 tests
â”‚   â””â”€â”€ README.md                       # Physics module docs
â”‚
â””â”€â”€ tools/
    â””â”€â”€ EvoEF2/                         # EvoEF2 binary + params
```

---

## 9. Quickstart Guide

### 9.1 Environment Setup

```bash
# Create environment
conda create -n flowtcr python=3.9
conda activate flowtcr

# Install core dependencies
pip install torch transformers biopython pandas numpy

# Install ESM-2 (required for Immuno-PLM)
pip install fair-esm

# Note: LoRA uses built-in implementation (no PEFT dependency)

# (Optional) Install wandb for experiment tracking
pip install wandb
```

**Memory Requirements**:
| Mode | VRAM | Notes |
|------|------|-------|
| BasicTokenizer | ~2 GB | For debugging only |
| ESM-2 (frozen) | ~8 GB | Good for testing |
| ESM-2 + LoRA | ~12 GB | Recommended for production |

### 9.2 Data Preparation

```bash
# 1. Prepare training data
head -3 data/trn.csv
# peptide,mhc,cdr3_b,h_v,h_j,l_v,l_j

# 2. Build scaffold bank
python -c "
import pandas as pd
df = pd.read_csv('data/trn.csv')
scaffolds = df.groupby(['h_v','h_j','l_v','l_j']).size().reset_index(name='count')
scaffolds.to_csv('data/scaffold_bank.csv', index=False)
print(f'Unique scaffolds: {len(scaffolds)}')
"

# 3. (Optional) Prepare PDB structures
mkdir -p data/pdb_structures
# Download from STCRDab / TCR3d
```

### 9.3 Training

```bash
# Step 1: Train Immuno-PLM with ESM-2 + LoRA (design target; uses in-house LoRA if no )
python flowtcr_fold/Immuno_PLM/train_plm.py     --data data/trn.csv     --use_esm --use_lora     --esm_model esm2_t33_650M_UR50D     --lora_rank 8     --batch_size 32     --epochs 100     --out_dir checkpoints/plm

# Step 1 (implemented subset): BasicTokenizer or frozen ESM features
python flowtcr_fold/Immuno_PLM/train_plm.py     --data data/trn.csv     --batch_size 32     --epochs 100     --out_dir checkpoints/plm

# Optional: use frozen ESM features if installed
python flowtcr_fold/Immuno_PLM/train_plm.py     --data data/trn.csv     --use_esm     --esm_model esm2_t6_8M_UR50D     --batch_size 32     --epochs 100     --out_dir checkpoints/plm


# Step 2: Train FlowTCR-Gen
python flowtcr_fold/FlowTCR_Gen/train_flow.py \
    --data data/trn.csv \
    --epochs 100

# (Optional) Step 3: Train TCRFold-Light
python flowtcr_fold/TCRFold_Light/train_with_energy.py \
    --pdb_dir data/pdb_structures
```

### 9.4 Inference

```bash
# Run design pipeline
python flowtcr_fold/FlowTCR_Gen/pipeline_impl.py \
    --peptide "GILGFVFTL" \
    --mhc "HLA-A*02:01"
```

---

## 10. Legacy Code References

This project builds upon validated components from previous work:

| Legacy Module | Location | Reused Components |
|---------------|----------|-------------------|
| **Topology Bias** | `conditioned/model.py` | Region/pair embeddings (lines 85-117) |
| **Hierarchical Pairs** | `psi_model/model.py` | `create_hierarchical_pairs`, Collapse token |
| **Evoformer** | `conditioned/src/Evoformer.py` | Triangle updates, Triangle attention |
| **Data Patterns** | `conditioned/data.py` | Masking, amino acid encoding |

---

## 11. Status & Roadmap (Plan v3.1)

### 11.1 Implementation Status

| Stage | Module | Status | Key Milestones |
|-------|--------|--------|----------------|
| 1 | **Immuno-PLM** | ğŸ”„ 70% | Dual InfoNCE + BCE pending; R@10 target 20-40% |
| 2 | **FlowTCR-Gen** | ğŸ”„ 40% | Collapse/pairs integrated; CFG + flow head pending |
| 3A | **TCRFold-Prophet (PPI)** | ğŸ”„ 30% | PDB download + FAPE training pending |
| 3B | **Energy Surrogate (E_Ï†)** | ğŸ”„ 20% | EvoEF2 batch processing ready; NN fitting pending |
| 3C | **TCR Finetune** | â³ 0% | Depends on 3A/3B completion |
| â€” | **End-to-end Pipeline** | ğŸ”„ 50% | Skeleton implemented; integration pending |

### 11.2 Execution Timeline (12-16 weeks)

| Week | Stage | Tasks | Milestone |
|------|-------|-------|-----------|
| W1-2 | Stage 1 | Dual InfoNCE + BCE + allele emb | R@10 > 20%, KL < baseline |
| W3-5 | Stage 2 | FlowTCRGen refactor + ODE + CFG | Recovery > 30%, PPL < 10 |
| W6-8 | Stage 3A/3B | PPI pretrain + energy fit | Corr > 0.6 with EvoEF2 |
| W9-10 | Stage 3C | TCR finetune + MC integration | Corr > 0.7 on TCR |
| W11-12 | Integration | End-to-end eval + paper draft | Full pipeline functional |
| W13+ | Exploratory | Guided ODE, grad-MC, self-play | Optional enhancements |

### 11.3 Immediate Priorities

1. ğŸ”´ **Stage 1**: Dual-group InfoNCE + multi-label BCE + gene-name cleanup
2. ğŸ”´ **Stage 2**: psiCLM â†’ FlowTCRGen refactor (x_t injection + flow head)
3. ğŸŸ¡ **Stage 3**: PDB download + EvoEF2 batch processing scripts

---

## References

- **EvoEF2**: Huang X, Pearce R, Zhang Y. Bioinformatics (2020), 36:1135-1142
- **ESM-2**: Lin Z, et al. Science (2023)
- **Flow Matching**: Lipman Y, et al. ICLR (2023)
- **psi_model**: Internal development (hierarchical pair embeddings)

---

**Last Updated**: 2025-12-01  
**Version**: 3.1  
**Maintainers**: FlowTCR-Fold Team
