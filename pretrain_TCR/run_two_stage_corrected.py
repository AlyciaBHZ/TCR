#!/usr/bin/env python3
"""
ä¿®æ­£çš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹
é˜¶æ®µ1: å¤§è§„æ¨¡æ— æ ‡æ³¨TCRæ•°æ®é¢„è®­ç»ƒ (50ä¸‡-100ä¸‡æ¡)
é˜¶æ®µ2: é«˜è´¨é‡æ ‡æ³¨æ•°æ®å¾®è°ƒ (22ä¸‡æ¡)
"""

import os
import sys
import subprocess
import argparse
import torch

def stage1_large_scale_pretraining():
    """
    é˜¶æ®µ1: å¤§è§„æ¨¡TCRæ•°æ®é¢„è®­ç»ƒ
    ç›®æ ‡: å­¦ä¹ é€šç”¨çš„TCRåºåˆ—è¡¨ç¤ºå’Œè¯­æ³•è§„å¾‹
    """
    print("ğŸš€ STAGE 1: LARGE-SCALE TCR PRETRAINING")
    print("="*60)
    print("ç›®æ ‡: ä»å¤§è§„æ¨¡TCRæ•°æ®å­¦ä¹ é€šç”¨è¡¨ç¤º")
    print("æ•°æ®: TCRdb + VDJdb_full + IEDB_full (50ä¸‡+ åºåˆ—)")
    print("ä»»åŠ¡: çº¯ç²¹çš„Masked Language Modeling")
    print("="*60)
    
    # æ£€æŸ¥å¤§è§„æ¨¡æ•°æ®æ˜¯å¦å‡†å¤‡å¥½
    large_data_path = '../data/large_scale_tcr_pretrain.csv'
    
    if not os.path.exists(large_data_path):
        print("âŒ å¤§è§„æ¨¡æ•°æ®é›†æœªæ‰¾åˆ°")
        print("\nè¯·å…ˆå‡†å¤‡å¤§è§„æ¨¡TCRæ•°æ®ï¼š")
        print("1. è¿è¡Œ: python pretrain_large_scale.py")
        print("2. æŒ‰ç…§æŒ‡å—ä¸‹è½½å’Œå¤„ç†æ•°æ®")
        print("3. ç„¶åé‡æ–°è¿è¡Œæ­¤è„šæœ¬")
        return False
    
    # è¿è¡Œå¤§è§„æ¨¡é¢„è®­ç»ƒ
    print("å¼€å§‹å¤§è§„æ¨¡é¢„è®­ç»ƒ...")
    try:
        result = subprocess.run([
            'python', 'pretrain_large_scale.py'
        ], check=True, capture_output=True, text=True)
        
        print("âœ… é˜¶æ®µ1å®Œæˆ: å¤§è§„æ¨¡é¢„è®­ç»ƒ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ é˜¶æ®µ1å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def stage2_high_quality_finetuning(pretrained_model_path):
    """
    é˜¶æ®µ2: é«˜è´¨é‡æ•°æ®å¾®è°ƒ
    ç›®æ ‡: å­¦ä¹ ç‰¹å®šçš„TCR-peptide-MHCåŠŸèƒ½å…³è”
    """
    print("\nğŸ¯ STAGE 2: HIGH-QUALITY DATA FINE-TUNING")
    print("="*60)
    print("ç›®æ ‡: å­¦ä¹ ç‰¹å®šçš„ç”Ÿç‰©åŠŸèƒ½å…³è”")
    print("æ•°æ®: æ‚¨çš„22ä¸‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®")
    print("ä»»åŠ¡: æ¡ä»¶åŒ–çš„TCR-peptide-MHCé¢„æµ‹")
    print("="*60)
    
    # æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹
    if not os.path.exists(pretrained_model_path):
        print(f"âŒ é¢„è®­ç»ƒæ¨¡å‹æœªæ‰¾åˆ°: {pretrained_model_path}")
        return False
    
    # æ£€æŸ¥é«˜è´¨é‡æ•°æ®
    high_quality_data = '../data/trn.csv'
    if not os.path.exists(high_quality_data):
        print(f"âŒ é«˜è´¨é‡è®­ç»ƒæ•°æ®æœªæ‰¾åˆ°: {high_quality_data}")
        return False
    
    print(f"åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {pretrained_model_path}")
    print(f"å¾®è°ƒæ•°æ®: {high_quality_data}")
    
    # è¿è¡Œå¾®è°ƒ
    try:
        result = subprocess.run([
            'python', 'finetune.py',
            '--pretrained_model', pretrained_model_path,
            '--freeze_strategy', 'partial',  # éƒ¨åˆ†å†»ç»“ç­–ç•¥
            '--learning_rate', '1e-5',       # å¾®è°ƒç”¨è¾ƒå°å­¦ä¹ ç‡
            '--batch_size', '256'            # é€‚ä¸­çš„batch size
        ], check=True, capture_output=True, text=True)
        
        print("âœ… é˜¶æ®µ2å®Œæˆ: é«˜è´¨é‡å¾®è°ƒ")
        return True
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ é˜¶æ®µ2å¤±è´¥: {e}")
        print(f"é”™è¯¯è¾“å‡º: {e.stderr}")
        return False

def analyze_data_strategy():
    """
    åˆ†ææ•°æ®ä½¿ç”¨ç­–ç•¥
    """
    print("ğŸ“Š DATA STRATEGY ANALYSIS")
    print("="*50)
    
    print("ä¼ ç»Ÿç­–ç•¥ (ä¹‹å‰çš„å»ºè®®):")
    print("  âŒ 22ä¸‡é«˜è´¨é‡æ•°æ®é¢„è®­ç»ƒ â†’ æ‰©å±•æ•°æ®å¾®è°ƒ")
    print("  é—®é¢˜: æµªè´¹äº†é«˜è´¨é‡æ ‡æ³¨ä¿¡æ¯")
    
    print("\næ­£ç¡®ç­–ç•¥ (æ‚¨çš„å»ºè®®):")
    print("  âœ… å¤§è§„æ¨¡æ— æ ‡æ³¨æ•°æ®é¢„è®­ç»ƒ â†’ 22ä¸‡é«˜è´¨é‡æ•°æ®å¾®è°ƒ")
    print("  ä¼˜åŠ¿:")
    print("    1. é¢„è®­ç»ƒå­¦ä¹ é€šç”¨TCRè¯­æ³•")
    print("    2. å¾®è°ƒå­¦ä¹ ç‰¹å®šåŠŸèƒ½å…³è”")
    print("    3. å……åˆ†åˆ©ç”¨é«˜è´¨é‡æ ‡æ³¨")
    print("    4. ç¬¦åˆç°ä»£é¢„è®­ç»ƒèŒƒå¼")
    
    print("\næ•°æ®è§„æ¨¡é¢„æœŸ:")
    print("  é˜¶æ®µ1é¢„è®­ç»ƒ: 50ä¸‡-100ä¸‡æ¡TCRåºåˆ—")
    print("  é˜¶æ®µ2å¾®è°ƒ: 22ä¸‡æ¡é«˜è´¨é‡åŠŸèƒ½æ ‡æ³¨")
    print("  æ€»è®¡: 70ä¸‡-120ä¸‡æ¡æ•°æ®")
    
    print("\nç†è®ºåŸºç¡€:")
    print("  1. å¤§è§„æ¨¡æ— ç›‘ç£é¢„è®­ç»ƒ â†’ é€šç”¨è¡¨ç¤º")
    print("  2. ä»»åŠ¡ç‰¹å®šæœ‰ç›‘ç£å¾®è°ƒ â†’ åŠŸèƒ½å…³è”")
    print("  3. è¿™æ­£æ˜¯BERT/GPTçš„æˆåŠŸæ¨¡å¼")

def main():
    parser = argparse.ArgumentParser(description='Two-Stage TCR Training Pipeline')
    parser.add_argument('--skip_stage1', action='store_true', 
                       help='Skip large-scale pretraining')
    parser.add_argument('--pretrained_model', type=str,
                       help='Path to pretrained model for stage 2')
    
    args = parser.parse_args()
    
    print("ğŸ§¬ psiCLM Two-Stage Training Pipeline")
    print("åŸºäºpsihÄ“ç†è®ºçš„TCRåºåˆ—ç”Ÿæˆæ¨¡å‹è®­ç»ƒ")
    print("="*60)
    
    # åˆ†æç­–ç•¥
    analyze_data_strategy()
    
    pretrained_model_path = None
    
    # é˜¶æ®µ1: å¤§è§„æ¨¡é¢„è®­ç»ƒ
    if not args.skip_stage1:
        success = stage1_large_scale_pretraining()
        if not success:
            print("âŒ æµç¨‹ç»ˆæ­¢: é˜¶æ®µ1å¤±è´¥")
            return
        
        pretrained_model_path = './saved_model/large_scale_pretrain/best_large_scale_pretrain'
    else:
        pretrained_model_path = args.pretrained_model
        if not pretrained_model_path:
            print("âŒ è·³è¿‡é˜¶æ®µ1æ—¶å¿…é¡»æä¾›é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„")
            return
    
    # é˜¶æ®µ2: é«˜è´¨é‡å¾®è°ƒ
    success = stage2_high_quality_finetuning(pretrained_model_path)
    if not success:
        print("âŒ æµç¨‹ç»ˆæ­¢: é˜¶æ®µ2å¤±è´¥")
        return
    
    print("\nğŸ‰ TWO-STAGE TRAINING COMPLETED!")
    print("="*50)
    print("æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š")
    print("1. é€šç”¨TCRåºåˆ—ç†è§£ (æ¥è‡ªå¤§è§„æ¨¡é¢„è®­ç»ƒ)")
    print("2. ç‰¹å®šåŠŸèƒ½é¢„æµ‹ (æ¥è‡ªé«˜è´¨é‡å¾®è°ƒ)")
    print("3. æ¡ä»¶åŒ–ç”Ÿæˆ (TCR-peptide-MHCå…³è”)")
    
    print("\nä¸‹ä¸€æ­¥å»ºè®®ï¼š")
    print("1. è¿è¡Œè¯„ä¼°è„šæœ¬æµ‹è¯•æ¨¡å‹æ€§èƒ½")
    print("2. ä½¿ç”¨attentionå¯è§†åŒ–éªŒè¯å­¦ä¹ æ•ˆæœ")
    print("3. è¿›è¡Œwet labå®éªŒéªŒè¯")

if __name__ == '__main__':
    main() 